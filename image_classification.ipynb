# Creating an IPython Notebook (.ipynb) file for the Image Classification using Neural Networks project



import json



# Defining the notebook structure

notebook_content = {

    "cells": [

        {

            "cell_type": "markdown",

            "metadata": {},

            "source": [

                "# Project: Image Classification using Neural Networks\n",

                "\n",

                "This project implements an image classification task using a Convolutional Neural Network (CNN) on the CIFAR-10 dataset."

            ]

        },

        {

            "cell_type": "code",

            "execution_count": 1,

            "metadata": {},

            "outputs": [],

            "source": [

                "import numpy as np\n",

                "import matplotlib.pyplot as plt\n",

                "from tensorflow.keras import datasets, layers, models\n",

                "from sklearn.metrics import classification_report, confusion_matrix\n",

                "import seaborn as sns"

            ]

        },

        {

            "cell_type": "markdown",

            "metadata": {},

            "source": [

                "## 1. Load CIFAR-10 Dataset\n",

                "The CIFAR-10 dataset is a collection of images used for training machine learning algorithms.\n",

                "It can be expressed as a set: \n",

                "$$D = \\{(X_i, y_i)\\}_{i=1}^{N}$$\n",

                "Where $X_i$ represents the image, and $y_i$ represents its corresponding label."

            ]

        },

        {

            "cell_type": "code",

            "execution_count": 2,

            "metadata": {},

            "outputs": [],

            "source": [

                "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()"

            ]

        },

        {

            "cell_type": "markdown",

            "metadata": {},

            "source": [

                "## 2. Normalize Pixel Values\n",

                "Normalization rescales pixel values to the range [0, 1]:\n",

                "$$X_{normalized} = \\frac{X}{255.0}$$"

            ]

        },

        {

            "cell_type": "code",

            "execution_count": 3,

            "metadata": {},

            "outputs": [],

            "source": [

                "X_train, X_test = X_train / 255.0, X_test / 255.0"

            ]

        },

        {

            "cell_type": "markdown",

            "metadata": {},

            "source": [

                "## 3. Build the CNN Model\n",

                "The model architecture consists of convolutional layers, pooling layers, and dense layers."

            ]

        },

        {

            "cell_type": "code",

            "execution_count": 4,

            "metadata": {},

            "outputs": [],

            "source": [

                "model = models.Sequential([\n",

                "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",

                "    layers.MaxPooling2D((2, 2)),\n",

                "    layers.Conv2D(64, (3, 3), activation='relu'),\n",

                "    layers.MaxPooling2D((2, 2)),\n",

                "    layers.Conv2D(64, (3, 3), activation='relu'),\n",

                "    layers.Flatten(),\n",

                "    layers.Dense(64, activation='relu'),\n",

                "    layers.Dense(10, activation='softmax')\n",

                "])"

            ]

        },

        {

            "cell_type": "markdown",

            "metadata": {},

            "source": [

                "### 4. Compile the Model\n",

                "The model is compiled with an optimizer and a loss function."

            ]

        },

        {

            "cell_type": "code",

            "execution_count": 5,

            "metadata": {},

            "outputs": [],

            "source": [

                "model.compile(optimizer='adam',\n",

                "              loss='sparse_categorical_crossentropy',\n",

                "              metrics=['accuracy'])"

            ]

        },

        {

            "cell_type": "markdown",

            "metadata": {},

            "source": [

                "### 5. Train the Model\n",

                "The model is trained for a specified number of epochs."

            ]

        },

        {

            "cell_type": "code",

            "execution_count": 6,

            "metadata": {},

            "outputs": [],

            "source": [

                "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"

            ]

        },

        {

            "cell_type": "markdown",

            "metadata": {},

            "source": [

                "### 6. Evaluate the Model\n",

                "After training, we evaluate the model on the test set."

            ]

        },

        {

            "cell_type": "code",

            "execution_count": 7,

            "metadata": {},

            "outputs": [],

            "source": [

                "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",

                "print(\"\\nTest accuracy:\", test_acc)"

            ]

        },

        {

            "cell_type": "markdown",

            "metadata": {},

            "source": [

                "### 7. Make Predictions\n",

                "The model predicts the classes of the test images."

            ]

        },

        {

            "cell_type": "code",

            "execution_count": 8,

            "metadata": {},

            "outputs": [],

            "source": [

                "y_pred = model.predict(X_test)\n",

                "y_pred_classes = np.argmax(y_pred, axis=1)"

            ]

        },

        {

            "cell_type": "markdown",

            "metadata": {},

            "source": [

                "### 8. Generate Classification Report\n",

                "This report displays precision, recall, and F1-score for each class."

            ]

        },

        {

            "cell_type": "code",

            "execution_count": 9,

            "metadata": {},

            "outputs": [],

            "source": [

                "print(classification_report(y_test, y_pred_classes))"

            ]

        },

        {

            "cell_type": "markdown",

            "metadata": {},

            "source": [

                "### 9. Confusion Matrix\n",

                "A confusion matrix summarizes the performance of the classification algorithm."

            ]

        },

        {

            "cell_type": "code",

            "execution_count": 10,

            "metadata": {},

            "outputs": [],

            "source": [

                "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",

                "\n",

                "# Plot confusion matrix\n",

                "plt.figure(figsize=(10, 7))\n",

                "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",

                "            xticklabels=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'],\n",

                "            yticklabels=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",

                "plt.ylabel('Actual')\n",

                "plt.xlabel('Predicted')\n",

                "plt.title('Confusion Matrix')\n",

                "plt.show()"

            ]

        }

    ],

    "metadata": {

        "kernelspec": {

            "display_name": "Python 3",

            "language": "python",

            "name": "python3"

        },

        "language_info": {

            "codemirror_mode": {

                "name": "ipython",

                "version": 3

            },

            "file_extension": ".py",

            "mimetype": "text/x-python",

            "name": "python",

            "nbconvert_exporter": "python",

            "pygments_lexer": "ipython3",

            "version": "3.8.5"

        }

    },

    "nbformat": 4,

    "nbformat_minor": 4

}



# Saving the notebook content to a .ipynb file

ipynb_file_path = '/mnt/data/image_classification_project.ipynb'

with open(ipynb_file_path, 'w') as f:

    json.dump(notebook_content, f)



ipynb_file_path
